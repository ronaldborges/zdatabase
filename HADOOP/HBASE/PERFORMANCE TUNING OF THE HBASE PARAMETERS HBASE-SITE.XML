#############################################################
# PERFORMANCE TUNING OF THE HBASE PARAMETERS HBASE-SITE.XML #
#############################################################

1. Table design

1.1 Pre-Creating Regions

By default, a region partition is automatically created when the HBase table is created. 
When data is imported, all HBase clients write data to this region, and the region is not split until the region is large enough. 
One way to speed up the batch writing speed is to create some empty regions in advance, so that when data is written to HBase, 
the data will be load balanced in the cluster according to the region partition.

$----------------------------------------------------------------------------------------------------------$

Java code

public static boolean createTable(HBaseAdmin admin, HTableDescriptor table, byte[][] splits)  
  throws IOException {  
  try {  
    admin.createTable(table, splits);  
    return true;  
  } catch (TableExistsException e) {  
    logger.info("table " + table.getNameAsString() + " already exists");  
    // the table already exists...  
    return false;  
  }  
}  
   
public static byte [] [] getHexSplits (String startKey, String endKey,  int  numRegions) {    
  byte[][] splits = new byte[numRegions-1][];  
  BigInteger lowestKey = new BigInteger(startKey, 16);  
  BigInteger highestKey = new BigInteger(endKey, 16);  
  BigInteger range = highestKey.subtract(lowestKey);  
  BigInteger regionIncrement = range.divide(BigInteger.valueOf(numRegions));  
  lowestKey = lowestKey.add(regionIncrement);  
  for(int i=0; i < numRegions-1;i++) {  
    BigInteger key = lowestKey.add(regionIncrement.multiply(BigInteger.valueOf(i)));  
    byte[] b = String.format("%016x", key).getBytes();  
    splits[i] = b;  
  }  
  return splits;  
}  

$----------------------------------------------------------------------------------------------------------$

1.2 Row Key

The row key in HBase is used to retrieve the records in the table and supports the following three methods:

Access through a single row key: Get operation according to a certain row key key value;
Scan through the range of the row key: that is, scan within this range by setting startRowKey and endRowKey;
Full table scan: Scan all rows in the entire table directly.
In HBase, the row key can be any string with a maximum length of 64KB. In practical applications, it is generally 10~100bytes. 
It is stored as a byte[] byte array and is generally designed as a fixed length .

The row key is stored in lexicographic order. 
Therefore, when designing the row key, make full use of this sorting feature, store the data that is frequently read together, 
and store the data that may be accessed recently.

For example: If the data recently written to the HBase table is most likely to be accessed, consider using the timestamp as part of the row key. 
Because it is lexicographically sorted, you can use Long.MAX_VALUE-timestamp as the row key. 
It can ensure that newly written data can be hit quickly when read.

1.3 Column Family

Don't define too many column families in one table. 
Currently, Hbase cannot handle tables with more than 2 to 3 column families. 
Because when a column family is flushed, its neighboring column family will also be flushed due to the correlation effect, 
which will eventually cause the system to generate more I/O. 
Interested students can perform actual tests on their HBase clusters and verify them from the test result data.

1.4 In Memory

When creating a table, you can use HColumnDescriptor.setInMemory(true) to put the table in the RegionServer's cache to ensure 
that it is hit by the cache when it is read.

1.5 Max Version

When creating a table, you can set the maximum version of the data in the table through HColumnDescriptor.setMaxVersions(int maxVersions). 
If you only need to save the latest version of the data, you can set setMaxVersions(1).

1.6 Time To Live

When creating a table, you can set the storage lifetime of the data in the table through HColumnDescriptor.setTimeToLive(int timeToLive), 
and expired data will be automatically deleted. For example, if you only need to store the data of the last two days, 
you can set setTimeToLive(2 * 24 * 60 * 60).

1.7 Compact & Split
In HBase, data is first written to WAL log (HLog) and memory (MemStore) when it is updated. 
The data in MemStore is sorted. When MemStore accumulates to a certain threshold, 
a new MemStore will be created and the old The MemStore is added to the flush queue and flushed to the disk by a separate thread to become a StoreFile. 
At the same time, the system will record a redo point in zookeeper, 
indicating that the changes before this moment have been persisted (minor compact) .

StoreFile is read-only and cannot be modified once it is created. Therefore, 
the update of Hbase is actually a continuous addition operation. When the StoreFile in a Store reaches a certain threshold, 
it will be merged (major compact) , and the modifications to the same key will be merged together to form a large StoreFile. 
When the size of the StoreFile reaches a certain threshold, it will of StoreFile divided (split), divided into two StoreFile.

Since the update of the table is constantly appended, 
when processing read requests, you need to access all StoreFile and MemStore in the Store and merge them according to the row key. 
Because StoreFile and MemStore are sorted, and StoreFile has an in-memory index , Usually the merge process is relatively fast.

In actual applications, you can consider manual major compaction if necessary, 
and merge the modifications of the same row key to form a large StoreFile. At the same time, 
the StoreFile can be set larger to reduce the occurrence of split.

2. Table write operation

2.1 Multiple HTable concurrent writing

Create multiple HTable clients for write operations to improve the throughput of writing data. An example:

$----------------------------------------------------------------------------------------------------------$

Java code

static final Configuration conf = HBaseConfiguration.create();  
static final String table_log_name = “user_log”;  
wTableLog = new HTable[tableN];  
for (int i = 0; i < tableN; i++) {  
    wTableLog[i] = new HTable(conf, table_log_name);  
    wTableLog[i].setWriteBufferSize(5 * 1024 * 1024); //5MB  
    wTableLog[i].setAutoFlush(false);  
}  

$----------------------------------------------------------------------------------------------------------$

2.2 HTable parameter setting

2.2.1 Auto Flush

By calling the HTable.setAutoFlush(false) method, the automatic flush of the HTable write client can be turned off, 
so that data can be written to HBase in batches, instead of performing one update when there is a put, 
only when the put fills the client write cache, Actually initiate a write request to the HBase server. 
Auto flush is turned on by default.

2.2.2 Write Buffer

The write buffer size of the HTable client can be set by calling the HTable.setWriteBufferSize(writeBufferSize) method. 
If the newly set buffer is smaller than the data in the current write buffer, the buffer will be flushed to the server. 
Among them, the unit of writeBufferSize is the number of bytes, which can be set according to the actual amount of data written.

2.2.3 WAL Flag

In HBae, when the client submits data to the RegionServer in the cluster (Put/Delete operation), 
it will first write the WAL (Write Ahead Log) log (ie HLog, all Regions on a RegionServer share the same HLog), 
only when the WAL After the log is successfully written, the MemStore is written again, 
and then the client is notified that the data submission is successful; if writing the WAL log fails, 
the client is notified that the submission failed. The advantage of this is that data recovery after the RegionServer goes down.

Therefore, for relatively unimportant data, 
you can call Put.setWriteToWAL(false) or Delete.setWriteToWAL(false) during Put/Delete operations to abandon writing WAL logs, 
thereby improving the performance of data writing.

It is worth noting that: carefully choose to close the WAL log, because in this case, 
once the RegionServer goes down, 
Put/Delete data will not be able to be restored based on the WAL log.

2.3 Batch write

A specified row key record can be written to HBase by calling the HTable.put(Put) method. 
Similarly, HBase provides another method: by calling the HTable.put(List<Put>) method, the specified row key can be listed in batches. 
The advantage of writing multiple rows of records is that batch execution requires only one network I/O overhead. 
This requires high real-time data and high network transmission RTT may bring significant performance improvement.

2.4 Multi-threaded concurrent writing

Open multiple HTable write threads on the client, and each write thread is responsible for the flush operation of an HTable object. 
This combination of timing flush and write buffer (writeBufferSize) can ensure that the data can be in a short time when the amount of data is small. 
Be flushed (for example, within 1 second), while ensuring that when the amount of data is large, flush in time when the write buffer is full. 
Here is a specific example:

$----------------------------------------------------------------------------------------------------------$

Java code

for (int i = 0; i < threadN; i++) {  
    Thread th = new Thread() {  
        public void run() {  
            while (true) {  
                try {  
                    sleep(1000); //1 second  
                } catch (InterruptedException e) {  
                    e.printStackTrace ();  
                }  
                                synchronized (wTableLog[i]) {  
                    try {  
                        wTableLog[i].flushCommits();  
                    } catch (IOException e) {  
                        e.printStackTrace ();  
                    }  
                }  
            }  
                }  
    };  
    th.setDaemon(true);  
    th.start();  
}  

$----------------------------------------------------------------------------------------------------------$

3. Read the meter operation

3.1 concurrent reading of multiple HTables

Create multiple HTable clients for read operations to improve the throughput of read data. An example:

$----------------------------------------------------------------------------------------------------------$

Java code

static final Configuration conf = HBaseConfiguration.create();  
static final String table_log_name = “user_log”;  
rTableLog = new HTable[tableN];  
for (int i = 0; i < tableN; i++) {  
    rTableLog[i] = new HTable(conf, table_log_name);  
    rTableLog[i].setScannerCaching(50);  
}  

$----------------------------------------------------------------------------------------------------------$

3.2 HTable parameter setting

3.2.1 Scanner Caching

By calling HTable.setScannerCaching(int scannerCaching), 
you can set the number of data items that HBase scanner can grab from the server at a time, one item at a time by default. 
By setting this value to a reasonable value, the time overhead of next() in the scan process can be reduced. 
The cost is that the scanner needs to maintain these cached rows through the client's memory.

3.2.2 Scan Attribute Selection

Specifying the required Column Family during scan can reduce the amount of network transmission data, 
otherwise the default scan operation will return all Column Family data in the entire row.

3.2.3 Close ResultScanner

After fetching data through scan, remember to close ResultScanner, 
otherwise RegionServer may have problems (corresponding Server resources cannot be released).

3.3 Batch reading

By calling the HTable.get(Get) method, you can get a row of records based on a specified row key. 
Similarly, HBase provides another method: By calling the HTable.get(List) method, 
you can get multiple rows in batches based on a specified row key list. 
Record, the advantage of doing this is batch execution, only one network I/O overhead is required, 
which may bring significant performance improvement in scenarios with high data real-time requirements and high network transmission RTT.

3.4 Multithreaded concurrent reading

Open multiple HTable reader threads on the client, and each reader thread is responsible for the get operation through the HTable object. 
The following is an example of multi-threaded concurrent reading of HBase to obtain the PV value of each minute of the shop in a day:

$----------------------------------------------------------------------------------------------------------$

Java code

public class  DataReaderServer {   
     //Get the entry function of the PV value of each minute of the store in a day  
     public static ConcurrentHashMap getUnitMinutePV(long uid, long startStamp, long endStamp){  
         long  min = startStamp;  
         int count = (int)((endStamp - startStamp) / (60*1000));  
         List lst = new ArrayList();  
         for (int i = 0; i <= count; i++) {  
            min = startStamp + i *  60  *  1000 ;  
            lst.add(uid + "_" + min);  
         }  
         return parallelBatchMinutePV(lst);  
     }  
      //Multi-threaded concurrent query, get minute PV value  
private static ConcurrentHashMap parallelBatchMinutePV(List lstKeys){  
        ConcurrentHashMap hashRet = new ConcurrentHashMap();  
        int parallel = 3;  
        List<List<String>> lstBatchKeys  = null;  
        if (lstKeys.size() < parallel ){  
            lstBatchKeys  = new ArrayList<List<String>>(1);  
            lstBatchKeys.add(lstKeys);  
        }  
        else{  
            lstBatchKeys  = new ArrayList<List<String>>(parallel);  
            for(int i = 0; i < parallel; i++  ){  
                List lst = new ArrayList();  
                lstBatchKeys.add(lst);  
            }  
   
            for(int i = 0 ; i < lstKeys.size() ; i ++ ){  
                lstBatchKeys.get(i%parallel).add(lstKeys.get(i));  
            }  
        }  
   
        List >> futures = new ArrayList >>(5);  
   
        ThreadFactoryBuilder builder = new ThreadFactoryBuilder();  
        builder.setNameFormat("ParallelBatchQuery");  
        ThreadFactory factory = builder.build();  
        ThreadPoolExecutor executor = (ThreadPoolExecutor) Executors.newFixedThreadPool(lstBatchKeys.size(), factory);  
   
        for(List keys : lstBatchKeys){  
            Callable< ConcurrentHashMap > callable = new BatchMinutePVCallable(keys);  
            FutureTask< ConcurrentHashMap > future = (FutureTask< ConcurrentHashMap >) executor.submit(callable);  
            futures.add(future);  
        }  
        executor.shutdown();  
   
        // Wait for all the tasks to finish  
        try {  
          boolean stillRunning = !executor.awaitTermination(  
              5000000, TimeUnit.MILLISECONDS);  
          if (stillRunning) {  
            try {  
                executor.shutdownNow();  
            } catch (Exception e) {  
                // TODO Auto-generated catch block  
                e.printStackTrace ();  
            }  
          }  
        } catch (InterruptedException e) {  
          try {  
              Thread.currentThread().interrupt();  
          } catch (Exception e1) {  
            // TODO Auto-generated catch block  
            e1.printStackTrace ();  
          }  
        }  
   
        // Look for any exception  
        for (Future f : futures) {  
          try {  
              if(f.get() != null)  
              {  
                  hashRet.putAll ((ConcurrentHashMap) f.get ());  
              }  
          } catch (InterruptedException e) {  
            try {  
                 Thread.currentThread().interrupt();  
            } catch (Exception e1) {  
                // TODO Auto-generated catch block  
                e1.printStackTrace ();  
            }  
          } catch (ExecutionException e) {  
            e.printStackTrace ();  
          }  
        }  
   
        return hashRet;  
    }  
     //One thread batch query, get minute PV value  
    protected static ConcurrentHashMap getBatchMinutePV(List lstKeys){  
        ConcurrentHashMap hashRet = null;  
        List lstGet = new ArrayList();  
        String[] splitValue = null;  
        for (String s : lstKeys) {  
            splitValue = s.split("_");  
            long uid = Long.parseLong(splitValue[0]);  
            long min = Long.parseLong(splitValue[1]);  
            byte[] key = new byte[16];  
            Bytes.putLong(key, 0, uid);  
            Bytes.putLong(key, 8, min);  
            Get g = new Get(key);  
            g.addFamily(fp);  
            lstGet.add(g);  
        }  
        Result[] res = null;  
        try {  
            res = tableMinutePV [rand.nextInt (tableN)]. get (lstGet);  
        } catch (IOException e1) {  
            logger.error("tableMinutePV exception, e=" + e1.getStackTrace());  
        }  
   
        if (res != null && res.length > 0) {  
            hashRet = new ConcurrentHashMap(res.length);  
            for (Result re : res) {  
                if (re != null && !re.isEmpty()) {  
                    try {  
                        byte[] key = re.getRow();  
                        byte[] value = re.getValue(fp, cp);  
                        if (key != null && value != null) {  
                            hashRet.put(String.valueOf(Bytes.toLong(key,  
                                    Bytes.SIZEOF_LONG)), String.valueOf(Bytes  
                                    .toLong(value)));  
                        }  
                    } catch (Exception e2) {  
                        logger.error(e2.getStackTrace());  
                    }  
                }  
            }  
        }  
   
        return hashRet;  
    }  
}  
//Call the interface class to implement the Callable interface  
class BatchMinutePVCallable implements Callable>{  
     private List keys;  
   
     public BatchMinutePVCallable(List lstKeys ) {  
         this.keys = lstKeys;  
     }  
   
     public ConcurrentHashMap call() throws Exception {  
         return  DataReadServer.getBatchMinutePV (keys);  
     }  
}  

$----------------------------------------------------------------------------------------------------------$

3.5 Cache query results

For application scenarios that frequently query HBase, you can consider caching in the application. 
When there is a new query request, first look it up in the cache. 
If it exists, return it directly without querying HBase; otherwise, initiate a read request query to HBase. 
Then cache the query results in the application. As for the cache replacement strategy, common strategies such as LRU can be considered.

3.6 block cache

The memory of Regionserver on HBase is divided into two parts, one part is Memstore, 
mainly used for writing; the other part is BlockCache, mainly used for reading.

The write request will be written to the Memstore first, and the Regionserver will provide a Memstore for each region. 
When the Memstore is full of 64MB, it will start flush to the disk. 
When the total size of Memstore exceeds the limit (heapsize * hbase.regionserver.global.memstore.upperLimit * 0.9), 
the flush process will be forcibly started, starting from the largest Memstore and flushing until it falls below the limit.

The read request first goes to the Memstore to check the data, if it is not found, 
it goes to the BlockCache, and then it goes to the disk if it is not found, and the read result is put into the BlockCache. 
Because BlockCache adopts the LRU strategy, after BlockCache reaches the upper limit (heapsize * hfile.block.cache.size * 0.85), 
it will start the elimination mechanism to eliminate the oldest batch of data.

There is a BlockCache and N Memstores on a Regionserver, and the sum of their sizes cannot be greater than or equal to heapsize * 0.8, 
otherwise HBase cannot be started. The default BlockCache is 0.2 and Memstore is 0.4. 
For systems that pay attention to read response time, BlockCache can be set larger, 
such as setting BlockCache=0.4, Memstore=0.39, to increase the hit rate of the cache.

For the BlockCache mechanism, please refer to here: HBase's Block cache, HBase's blockcache mechanism, 
calculation and use of the cache in hbase.

4. Data calculation

4.1 Server-side calculation
Coprocessor runs on the HBase RegionServer server, 
and each Region maintains a reference to its related coprocessor implementation class. 
The coprocessor class can be loaded through the local jar in the classpath on the RegionServer or the HDFS classloader.

Currently, several coprocessors have been provided:

Coprocessor: Provides hooks for region management, such as open/close/split/flush/compact of the region;
RegionObserver: Provides hooks for monitoring table-related operations from the client, such as table get/put/scan/delete, etc.;
Endpoint: Provides command triggers that can execute arbitrary functions on the region. 
An example of use is column aggregation on the RegionServer side. Here is a code example.
The above are just some basic introductions about coprocessor. 
I have no experience in its actual use, and I don't know its availability and performance data. 
Interested students can try it, and welcome to discuss.

4.2 Write end calculation

4.2.1 Count

HBase itself can be regarded as a Key-Value storage system that can be scaled horizontally, 
but its own computing power is limited (Coprocessor can provide certain server-side calculations). 
Therefore, when using HBase, it often needs to be performed from the writing side or the reading side. 
Calculate, and then return the final calculation result to the caller. Give two simple examples:

PV calculation: Maintain the update of PV value by accumulating the count in the memory of the HBase write end. 
At the same time, in order to achieve persistence, 
the PV calculation result is synchronized to HBase periodically (such as 1 second), 
so that the query end will have a maximum of 1 second The delay of the clock can see the PV result of the second delay.
Minute PV calculation: Combined with the PV calculation method mentioned above, 
the current cumulative PV value is written into HBase every minute according to rowkey + minute as the new rowkey, 
and then the cumulative value of each minute before the day is obtained through scan on the query side PV value, 
and then successively subtract the accumulated PV value of two minutes before and after, 
get the current PV value in one minute, and finally get the PV value in each minute of the day.

4.2.2 Deduplication

The calculation of UV is an example of de-duplication calculation. There are two situations:

If the memory can accommodate, you can maintain all the existing UV logos in the Hash table. 
Whenever a new logo comes in, you can quickly find the Hash to determine whether it is a new UV. 
If it is, the UV value is increased by 1, otherwise the UV value is not. change. In addition, 
in order to achieve persistence or provide for query interface use, 
you can periodically (such as 1 second) to synchronize the UV calculation results to HBase.
If the memory cannot be accommodated, you can consider using Bloom Filter to achieve it, 
so as to reduce the memory usage as much as possible. In addition to UV calculation, 
judging whether the URL exists is also a typical application scenario.

4.3 Reading calculation

If the response time requirements are more demanding (such as a single http request to be returned in milliseconds), 
I personally feel that the reader should not do too much complicated calculation logic, 
and try to achieve a single function of the reader: that is, 
from the HBase RegionServer After reading the data (scan or get method), 
perform simple splicing according to the data format and directly return it to the front end for use. Of course, 
if the response time requirements are general or business characteristics require, 
some calculation logic can also be performed on the reading end.

5. Summary
As a Key-Value storage system, HBase is not a panacea, it has its own unique place. 
Therefore, when making applications based on it, 
we often need to optimize and improve from many aspects (table design, table reading operation, table writing operation, data calculation, etc.), 
and sometimes even need to configure and optimize HBase from the system level, 
and more You can even optimize HBase itself. This belongs to a different level category.

In short, in general, when optimizing the system, 
first locate the bottleneck that affects the performance of your program, 
and then perform targeted optimization. 
If the optimization meets your expectations, then you can stop the optimization; otherwise, 
continue to look for new bottlenecks and start new optimizations until the performance requirements are met.

###############################################################################################################################################################
# HBASE CONFIGURATION FILE hbase-site.xml #####################################################################################################################
###############################################################################################################################################################

This XML file does not appear to have any style information associated with it. The document tree is shown below.
<configuration>
<link type="text/css" rel="stylesheet" id="dark-mode-general-link"/>
<link type="text/css" rel="stylesheet" id="dark-mode-custom-link"/>
<style lang="en" type="text/css" id="dark-mode-custom-style"/>
<property>
<name>dfs.journalnode.rpc-address</name>
<value>0.0.0.0:8485</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>io.storefile.bloom.block.size</name>
<value>131072</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.ipc.rpc.class</name>
<value>org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.maxtaskfailures.per.tracker</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.client.max-cached-nodemanagers-proxies</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.speculative.retry-after-speculate</name>
<value>15000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.rest.threads.min</name>
<value>2</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.rs.cacheblocksonwrite</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ha.health-monitor.connect-retry-interval.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.work-preserving-recovery.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.mmap.cache.size</name>
<value>256</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.read-lock-reporting-threshold-ms</name>
<value>5000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.markreset.buffer.percent</name>
<value>0.0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>/home/hadoop/data/dataNode</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.max-age-ms</name>
<value>604800000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.lazypersist.file.scrub.interval.sec</name>
<value>300</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.ubertask.enable</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.delegation.token.renew-interval</name>
<value>86400000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log-aggregation.compression-type</name>
<value>none</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.replication.considerLoad</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.complete.cancel.delegation.tokens</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.upgrade.domain.factor</name>
<value>${dfs.replication}</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.datestring.cache.size</name>
<value>200000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.security.kms.client.authentication.retry-count</name>
<value>1</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.ssl.enabled.protocols</name>
<value>TLSv1,SSLv2Hello,TLSv1.1,TLSv1.2</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.status.multicast.address.ip</name>
<value>226.1.1.3</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.retrycache.heap.percent</name>
<value>0.03f</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.top.window.num.buckets</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.address</name>
<value>${yarn.resourcemanager.hostname}:8030</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.http.cross-origin.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.client.file-block-storage-locations.num-threads</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.balance.bandwidthPerSec</name>
<value>10m</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.proxy-user-privileges.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.decommission.max.concurrent.tracked.nodes</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.fetch.retry.enabled</name>
<value>${yarn.nodemanager.recovery.enabled}</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>io.mapfile.bloom.error.rate</name>
<value>0.005</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resourcemanager.minimum.version</name>
<value>NONE</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.nodemanagers.heartbeat-interval-ms</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.secondary.namenode.kerberos.internal.spnego.principal</name>
<value>${dfs.web.authentication.kerberos.principal}</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.http.cross-origin.allowed-headers</name>
<value>X-Requested-With,Content-Type,Accept,Origin</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.regionserver.thread.compaction.throttle</name>
<value>2684354560</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.delete.debug-delay-sec</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.write-lock-reporting-threshold-ms</name>
<value>5000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.read.shortcircuit.streams.cache.size</name>
<value>256</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.image.transfer.bandwidthPerSec</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.scheduler.maximum-allocation-vcores</name>
<value>4</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hfile.block.bloom.cacheonwrite</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.quorum</name>
<value>hadoopmaster1,hadoopslave1,hadoopslave2,hadoopslave3,hadoopslave4,hadoopslave5,hadoopslave6,hadoopslave7,hadoopslave8,hadoopslave9</value>
<final>false</final>
<source>hbase-site.xml</source>
</property>
<property>
<name>hbase.http.staticuser.user</name>
<value>dr.stack</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.service.handler.count</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.address</name>
<value>${yarn.timeline-service.hostname}:10200</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>ipc.maximum.response.length</name>
<value>134217728</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.hdfs-servers</name>
<value>${fs.defaultFS}</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.task.profile.reduce.params</name>
<value>${mapreduce.task.profile.params}</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.property.syncLimit</name>
<value>5</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.fs-limits.min-block-size</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ftp.stream-buffer-size</name>
<value>4096</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.client.use.legacy.blockreader.local</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.http.cross-origin.allowed-methods</name>
<value>GET,POST,HEAD</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.short.circuit.shared.memory.watcher.interrupt.check.ms</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.directoryscan.threads</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.buffer.dir</name>
<value>${hadoop.tmp.dir}/s3a</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.client.application-client-protocol.poll-interval-ms</name>
<value>200</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.leveldb-timeline-store.path</name>
<value>${hadoop.tmp.dir}/yarn/timeline</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.split.metainfo.maxsize</name>
<value>10000000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.edits.noeditlogchannelflush</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.fast.upload.buffer</name>
<value>disk</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>s3native.bytes-per-checksum</name>
<value>512</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.rest.filter.classes</name>
<value>org.apache.hadoop.hbase.rest.filter.GzipFilter</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.client.failover-retries-on-socket-timeouts</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.sensitive-config-keys</name>
<value> secret$ password$ ssl.keystore.pass$ fs.s3.*[Ss]ecret.?[Kk]ey fs.azure.account.key.* credential$ oauth.*token$ hadoop.security.sensitive-config-keys </value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.startup.delay.block.deletion.sec</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.user.provider.user.pattern</name>
<value>^[A-Za-z_][A-Za-z0-9._-]*[$]?$</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.client.retry-interval-ms</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.key.bitlength</name>
<value>128</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.wal.async.event-loop.config</name>
<value>global-event-loop</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>hadoop.http.authentication.type</name>
<value>simple</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.path.based.cache.refresh.interval.ms</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.local.clientfactory.class.name</name>
<value>org.apache.hadoop.mapred.LocalClientFactory</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.max.full.block.report.leases</name>
<value>6</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.cache.revocation.timeout.ms</name>
<value>900000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ipc.client.connection.maxidletime</name>
<value>10000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ipc.server.max.connections</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.recovery.store.leveldb.path</name>
<value>${hadoop.tmp.dir}/mapred/history/recoverystore</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.safemode.threshold-pct</name>
<value>0.999f</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hfile.block.cache.size</name>
<value>0.4</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.s3a.multipart.purge.age</name>
<value>86400</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.mob.compaction.batch.size</name>
<value>100</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.num.checkpoints.retained</name>
<value>2</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.hregion.memstore.mslab.enabled</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.client.best-effort</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.ubertask.maxmaps</name>
<value>9</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.stale.datanode.interval</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage</name>
<value>90.0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.ifile.readahead.bytes</name>
<value>4194304</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.uploader.server.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.admin.address</name>
<value>0.0.0.0:10033</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>s3.client-write-packet-size</name>
<value>65536</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.master.port</name>
<value>16000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.block.access.token.lifetime</name>
<value>600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.resource.cpu-vcores</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.input.lineinputformat.linespermap</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.regionserver.checksum.verify</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.num.extra.edits.retained</name>
<value>1000000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.security.visibility.mutations.checkauths</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.input.buffer.percent</name>
<value>0.70</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.http.staticuser.user</name>
<value>dr.who</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.maxattempts</name>
<value>4</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.search.filter.user</name>
<value>(&(objectClass=user)(sAMAccountName={0}))</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.admin.acl</name>
<value>*</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.workaround.non.threadsafe.getpwuid</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.client.context</name>
<value>default</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.map.maxattempts</name>
<value>4</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.entity-group-fs-store.active-dir</name>
<value>/tmp/entity-file-history/active</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.zk-retry-interval-ms</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.cleaner.interval-ms</name>
<value>86400000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.datanode.drop.cache.behind.reads</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.server.versionfile.writeattempts</name>
<value>3</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.balancer.address</name>
<value>0.0.0.0:0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.permissions.superusergroup</name>
<value>supergroup</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.is.minicluster</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.application.classpath</name>
<value>$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*,$HADOOP_YARN_HOME/share/hadoop/yarn/*,$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>fs.s3n.block.size</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.registry.system.acls</name>
<value>sasl:yarn@, sasl:mapred@, sasl:hdfs@</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.lock.suppress.warning.interval</name>
<value>10s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.list.cache.pools.num.responses</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.node-labels.provider.fetch-timeout-ms</name>
<value>1200000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.leaderport</name>
<value>3888</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.datanode.slow.io.warning.threshold.ms</name>
<value>300</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.store.in-memory.check-period-mins</name>
<value>720</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.multiobjectdelete.enable</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.master.info.port</name>
<value>16010</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-blocks-per-file</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.map.skip.proc-count.auto-incr</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.vmem-check-enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.authentication</name>
<value>simple</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.skip.proc-count.auto-incr</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.cpu.vcores</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>net.topology.node.switch.mapping.impl</name>
<value>org.apache.hadoop.net.ScriptBasedMapping</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3.sleepTimeSeconds</name>
<value>10</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.ttl-ms</name>
<value>604800000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.root-dir</name>
<value>/sharedcache</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.keytab</name>
<value>/etc/krb5.keytab</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.container.liveness-monitor.interval-ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.mob.cache.evict.period</name>
<value>3600</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.posix.attr.gid.name</name>
<value>gidNumber</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</name>
<value>/hadoop-yarn</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.replication.considerLoad.factor</name>
<value>2.0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>s3.bytes-per-checksum</name>
<value>512</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.regionserver.dns.nameserver</name>
<value>default</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.ssl.require.client.cert</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.journalnode.http-address</name>
<value>0.0.0.0:8480</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.output.fileoutputformat.compress</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.http.client.retry.max.attempts</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.ha.automatic-failover.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.ipc.server.callqueue.read.ratio</name>
<value>0</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.node-labels.provider.fetch-interval-ms</name>
<value>1800000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.server.keyvalue.maxsize</name>
<value>10485760</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.cluster.distributed</name>
<value>true</value>
<final>false</final>
<source>hbase-site.xml</source>
</property>
<property>
<name>hbase.rootdir</name>
<value>hdfs://hadoopmaster1:9000/user/hadoop/hbase</value>
<final>false</final>
<source>hbase-site.xml</source>
</property>
<property>
<name>dfs.namenode.metrics.logger.period.seconds</name>
<value>600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.max.threads</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.invalidate.work.pct.per.iteration</name>
<value>0.32f</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>s3native.client-write-packet-size</name>
<value>65536</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.max-lock-hold-to-release-lease-ms</name>
<value>25</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
<value>DEFAULT</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.client.submit.file.replication</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.job.committer.commit-window</name>
<value>10000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.sleep-delay-before-sigkill.ms</name>
<value>250</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.env-whitelist</name>
<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.hstore.compaction.ratio.offpeak</name>
<value>5.0F</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.acls.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>0.0.0.0:50090</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.map.speculative</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.job.speculative.slowtaskthreshold</name>
<value>1.0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.cgroups.mount</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.auth.token.max.lifetime</name>
<value>604800000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.regionserver.msginterval</name>
<value>3000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.http.policy</name>
<value>HTTP_ONLY</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.ipc.client.fallback-to-simple-auth-allowed</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ipc.client.low-latency</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3a.paging.maximum</name>
<value>5000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jvm.system-properties-to-log</name>
<value>os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.kerberos.min.seconds.before.relogin</name>
<value>60</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.rest.threads.max</name>
<value>100</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.nodemanager-connect-retries</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3.buffer.dir</name>
<value>${hadoop.tmp.dir}/s3</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.snapshot.enabled</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.dynamic.jars.dir</name>
<value>${hbase.rootdir}/lib</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.defaults.for.version</name>
<value>2.2.6</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>io.native.lib.available</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.heartbeat.recheck-interval</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.done-dir</name>
<value>${yarn.app.mapreduce.am.staging-dir}/history/done</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.regions.slop</name>
<value>0.001</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.retry.interval.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.reducer.unconditional-preempt.delay.sec</name>
<value>300</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.avoid.write.stale.datanode</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.txns</name>
<value>1000000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.ssl.hostname.verifier</name>
<value>DEFAULT</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.task.timeout</name>
<value>600000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.client.max.perserver.tasks</name>
<value>2</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.configuration.file-system-based-store</name>
<value>/yarn/conf</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.disk-health-checker.interval-ms</name>
<value>120000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>adl.feature.ownerandgroup.enableupn</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.journalnode.https-address</name>
<value>0.0.0.0:8481</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.groups.cache.secs</name>
<value>300</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.input.fileinputformat.split.minsize</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.datanode.sync.behind.writes</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.minicluster.control-resource-monitoring</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.fail-fast</name>
<value>${yarn.fail-fast}</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>zookeeper.session.timeout</name>
<value>90000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.full.block.report.lease.length.ms</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.balancer.keytab.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.port</name>
<value>13562</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.rpc.protection</name>
<value>authentication</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.client.https.keystore.resource</name>
<value>ssl-client.xml</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.list.encryption.zones.num.responses</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.client.failover-proxy-provider</name>
<value>org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.recovery.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.balancer.period</name>
<value>300000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ipc.client.tcpnodelay</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.ha.tail-edits.period</name>
<value>60</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.drop.cache.behind.writes</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3.maxRetries</name>
<value>4</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jobtracker.address</name>
<value>local</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.http.authentication.kerberos.principal</name>
<value>HTTP/_HOST@LOCALHOST</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.posix.attr.uid.name</name>
<value>uidNumber</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>nfs.server.port</name>
<value>2049</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.address</name>
<value>${yarn.resourcemanager.hostname}:8088</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.task.profile.reduces</name>
<value>0-2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.client.max-retries</name>
<value>30</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.am.max-attempts</name>
<value>2</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.hstore.blockingWaitTime</name>
<value>90000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>nfs.dump.dir</name>
<value>/tmp/.hdfs-nfs</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.client.pause</name>
<value>100</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.client.write.buffer</name>
<value>2097152</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.bytes-per-checksum</name>
<value>512</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.end-notification.max.retry.interval</name>
<value>5000</value>
<final>true</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>ipc.client.connect.retry.interval</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3a.multipart.size</name>
<value>100M</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.command-opts</name>
<value>-Xmx1024m</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.process-kill-wait.ms</name>
<value>2000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.rpc.timeout</name>
<value>60000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.state-store-class</name>
<value>org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.safemode.min.datanodes</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.client.fd-clean-interval-secs</name>
<value>60</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.thrift.maxWorkerThreads</name>
<value>1000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.job.speculative.minimum-allowed-tasks</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.write.stale.datanode.ratio</name>
<value>0.5f</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.jetty.logs.serve.aliases</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.fetch.retry.timeout-ms</name>
<value>30000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.du.interval</name>
<value>600000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.offpeak.end.hour</name>
<value>-1</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.node-labels.provider.fetch-interval-ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.admin.address</name>
<value>0.0.0.0:8047</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.acl.reservation-enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.random.device.file.path</name>
<value>/dev/urandom</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.task.merge.progress.records</name>
<value>10000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.region.replica.replication.enabled</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-metrics.period-ms</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.registry.secure</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.ssl.client.conf</name>
<value>ssl-client.xml</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.counters.max</name>
<value>120</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.localizer.fetch.thread-count</name>
<value>4</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>io.mapfile.bloom.size</name>
<value>1048576</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.localizer.client.thread-count</name>
<value>5</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.automatic.close</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.task.profile</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.recovery.compaction-interval-secs</name>
<value>3600</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.edit.log.autoroll.multiplier.threshold</name>
<value>2.0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.task.combine.progress.records</name>
<value>10000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.ssl.file.buffer.size</name>
<value>65536</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.client.job.max-retries</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.swift.impl</name>
<value>org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.container.log.backups</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.hstore.bytes.per.checksum</name>
<value>16384</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction</name>
<value>0.75f</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.hstore.flusher.count</name>
<value>2</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.minicluster.fixed.ports</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.backup.address</name>
<value>0.0.0.0:50100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.https.need-auth</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.app-submission.cross-platform</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.ttl-enable</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.user.home.dir.prefix</name>
<value>/user</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.rest-csrf.browser-useragents-regex</name>
<value>^Mozilla.*,^Opera.*</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.keytab</name>
<value>/etc/krb5.keytab</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log-aggregation.policy.class</name>
<value>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.client.application-client-protocol.poll-timeout-ms</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.ui-actions.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.xattrs.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.write.exclude.nodes.cache.expiry.interval.millis</name>
<value>600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.client-server.address</name>
<value>0.0.0.0:8045</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.datanode.registration.ip-hostname-check</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.image.transfer.chunksize</name>
<value>65536</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.webapp.cross-origin.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.instrumentation.requires.admin</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>io.compression.codec.bzip2.library</name>
<value>system-native</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.name.dir.restore</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.client.retries.number</name>
<value>45</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>dfs.namenode.resource.checked.volumes.minimum</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.ssl.keystores.factory.class</name>
<value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.list.cache.directives.num.responses</name>
<value>100</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.image.transfer-bootstrap-standby.bandwidthPerSec</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.status.multicast.address.port</name>
<value>16100</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.ftp.host</name>
<value>0.0.0.0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.task.exit.timeout</name>
<value>60000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.hstore.checksum.algorithm</name>
<value>CRC32C</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>s3.blocksize</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>s3native.stream-buffer-size</name>
<value>4096</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.datanode.dns.nameserver</name>
<value>default</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.memory-mb</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.task.userlog.limit.kb</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.security.crypto.codec.classes.aes.ctr.nopadding</name>
<value>org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.hstore.compaction.throughput.higher.bound</name>
<value>104857600</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.speculative</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.node-labels.fs-store.impl.class</name>
<value>org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.caller.context.max.size</name>
<value>128</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.replication.max</name>
<value>512</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.replication</name>
<value>3</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.client.failover-retries</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.cpu-vcores</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.recovery.enable</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.server.thread.wakefrequency</name>
<value>10000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>nfs.exports.allowed.hosts</name>
<value>* rw</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.lease.recovery.timeout</name>
<value>900000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.checksum.algo.impl</name>
<value>org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.coordinated.state.manager.class</name>
<value>org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.memory.limit.percent</name>
<value>0.25</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>file.replication</name>
<value>1</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.reduce.shuffle.consumer.plugin.class</name>
<value>org.apache.hadoop.mapreduce.task.reduce.Shuffle</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.task.local-fs.write-limit.bytes</name>
<value>-1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.list.openfiles.num.responses</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.log.level</name>
<value>INFO</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hfile.format.version</name>
<value>3</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.datanode.fsdatasetcache.max.threads.per.volume</name>
<value>4</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.am.max-attempts</name>
<value>2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.connection-keep-alive.timeout</name>
<value>5</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.replication.source.maxthreads</name>
<value>10</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.fuse.timer.period</name>
<value>5</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.reduces</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.connection.timeout.ms</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.thrift.minWorkerThreads</name>
<value>16</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.dns.interface</name>
<value>default</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.amrmproxy.client.thread-count</name>
<value>25</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.job.task.listener.thread-count</name>
<value>30</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.store.class</name>
<value>org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>s3native.replication</name>
<value>3</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.http.client.retry.policy.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.hstore.compaction.max.size</name>
<value>9223372036854775807</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.snapshot.restore.failsafe.name</name>
<value>hbase-failsafe-{snapshot.name}-{restore.timestamp}</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.permissions.umask-mode</name>
<value>022</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.node-ip-cache.expiry-interval-secs</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.cluster.local.dir</name>
<value>${hadoop.tmp.dir}/mapred/local</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.client.output.filter</name>
<value>FAILED</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.pmem-check-enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.failover.connection.retries.on.timeouts</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ftp.replication</name>
<value>3</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.hstore.blockingStoreFiles</name>
<value>16</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.search.attr.member</name>
<value>member</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.regionserver.hlog.reader.impl</name>
<value>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.s3a.max.total.tasks</name>
<value>5</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.replication.work.multiplier.per.iteration</name>
<value>2</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.fs.state-store.num-retries</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.leveldb-state-store.path</name>
<value>${hadoop.tmp.dir}/yarn/timeline</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.resource-tracker.address</name>
<value>${yarn.resourcemanager.hostname}:8031</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.pcores-vcores-multiplier</name>
<value>1.0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.master.info.bindAddress</name>
<value>0.0.0.0</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.edits.dir</name>
<value>${dfs.namenode.name.dir}</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.monitor.enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.trash.checkpoint.interval</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.retry.times</name>
<value>5</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.client.read.shortcircuit.streams.cache.expiry.ms</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>s3.stream-buffer-size</name>
<value>4096</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3a.connection.maximum</name>
<value>15</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.security.dns.log-slow-lookups.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>file.client-write-packet-size</name>
<value>65536</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.reformat.disabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.shell.missing.defaultFs.warning</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.status.listener.class</name>
<value>org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-directory-items</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.path.based.cache.block.map.allocation.percent</name>
<value>0.25</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.impl</name>
<value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.windows-container.memory-limit.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.dir</name>
<value>file://${hadoop.tmp.dir}/dfs/namesecondary</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.regionserver.dns.interface</name>
<value>default</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.remote-app-log-dir</name>
<value>/tmp/logs</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.retry-delay.max.ms</name>
<value>60000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>io.map.index.interval</name>
<value>128</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.replication.interval</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.rest.port</name>
<value>8080</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-localizer.java.opts</name>
<value>-Xmx256m</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.regionserver.handler.count</name>
<value>30</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.ssl.server.conf</name>
<value>ssl-server.xml</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.hregion.percolumnfamilyflush.size.lower.bound.min</name>
<value>16777216</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.rpc.socket.factory.class.default</name>
<value>org.apache.hadoop.net.StandardSocketFactory</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.client.socket.send.buffer.size</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.minicluster.yarn.nodemanager.resource.memory-mb</name>
<value>4096</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.client.max-retries</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.address</name>
<value>${yarn.nodemanager.hostname}:0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.webapp.https.address</name>
<value>0.0.0.0:19890</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.lifeline.handler.ratio</name>
<value>0.10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.ipc.server.callqueue.scan.ratio</name>
<value>0</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.datanode.max.transfer.threads</name>
<value>4096</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ha.failover-controller.graceful-fence.rpc-timeout.ms</name>
<value>5000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.datanode.ipc.address</name>
<value>0.0.0.0:50020</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.delayed.delegation-token.removal-interval-ms</name>
<value>30000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.kerberos.principal.pattern</name>
<value>*</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.mob.compaction.chore.period</name>
<value>604800</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.client.cached.conn.retry</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ipc.maximum.data.length</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.backup.http-address</name>
<value>0.0.0.0:50105</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.master</name>
<value>hadoopmaster1:60010</value>
<final>false</final>
<source>hbase-site.xml</source>
</property>
<property>
<name>mapreduce.job.finish-when-all-reducers-done</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.bulkload.retries.number</name>
<value>10</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.period</name>
<value>3600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.providers.combined</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.task.attempt.id</name>
<value>hb_m_hadoopmaster1,16000,1609789739348</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>hbase.regionserver.minorcompaction.pagecache.drop</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.hregion.max.filesize</name>
<value>10737418240</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.datanode.shared.file.descriptor.paths</name>
<value>/dev/shm,/tmp</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.master.loadbalancer.class</name>
<value>org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.http.policy</name>
<value>HTTP_ONLY</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.groups.cache.warn.after.ms</name>
<value>5000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.datanode.directoryscan.throttle.limit.ms.per.sec</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.fs.state-store.retry-interval-ms</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-xattrs-per-inode</name>
<value>32</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.zk-acl</name>
<value>world:anyone:rwcda</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.transfer.socket.send.buffer.size</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource-monitor.interval-ms</name>
<value>3000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.support.allow.format</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.mob.delfile.max.count</name>
<value>3</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.detect-hardware-capabilities</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.app-checker.class</name>
<value>org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.entity-group-fs-store.retain-seconds</name>
<value>604800</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.webapp.https.address</name>
<value>0.0.0.0:8044</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.max-retries</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.amrmproxy.enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms</name>
<value>20</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>zookeeper.znode.acl.parent</name>
<value>acl</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.status.publisher.class</name>
<value>org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.fs.state-store.retry-policy-spec</name>
<value>2000, 500</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.master.procedurewalcleaner.ttl</name>
<value>604800000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.tmp.dir</name>
<value>./tmp</value>
<final>false</final>
<source>hbase-site.xml</source>
</property>
<property>
<name>fs.s3a.fast.upload</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.committer.setup.cleanup.needed</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.datanode.cache.revocation.polling.ms</name>
<value>500</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.end-notification.retry.attempts</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.state-store.max-completed-applications</name>
<value>${yarn.resourcemanager.max-completed-applications}</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.http.max.threads</name>
<value>16</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.map.output.compress</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.client.localityCheck.threadPoolSize</name>
<value>2</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.hosts.provider.classname</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.cleaner.enable</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.job.running.reduce.limit</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>io.seqfile.local.dir</name>
<value>${hadoop.tmp.dir}/io/local</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.blockreport.split.threshold</name>
<value>1000000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.read.timeout</name>
<value>180000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.job.queuename</name>
<value>default</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.http.client.failover.sleep.base.millis</name>
<value>500</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.unsafe.stream.capability.enforce</name>
<value>false</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>dfs.datanode.scan.period.hours</name>
<value>504</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ipc.client.connect.max.retries</name>
<value>10</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.staging-dir</name>
<value>/tmp/hadoop-yarn/staging</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.display.keys</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.resources-handler.class</name>
<value>org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.client.job.retry-interval</name>
<value>2000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.leveldb-timeline-store.read-cache-size</name>
<value>104857600</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>io.file.buffer.size</name>
<value>4096</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.cross-origin.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs</name>
<value>86400</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log.deletion-threads-count</name>
<value>4</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>ha.zookeeper.parent-znode</name>
<value>/hadoop-ha</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>tfile.io.chunk.size</name>
<value>1048576</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.keytab</name>
<value>/etc/krb5.keytab</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.node-labels.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.viewfs.rename.strategy</name>
<value>SAME_MOUNTPOINT</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.acl.enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB</name>
<value>org.apache.hadoop.ipc.ProtobufRpcEngine</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>hbase.regionserver.regionSplitLimit</name>
<value>1000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.directory.search.timeout</name>
<value>10000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.version</name>
<value>1.0f</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.socket.read-timeout</name>
<value>60s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.token.tracking.ids.enabled</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.thrift.maxQueuedRequests</name>
<value>1000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.datanode.block-pinning.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.map.output.compress.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>s3.replication</name>
<value>3</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.root</name>
<value>/registry</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>tfile.fs.input.buffer.size</name>
<value>262144</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.http-authentication.type</name>
<value>simple</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>ha.failover-controller.graceful-fence.connection.retries</name>
<value>1</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.offpeak.start.hour</name>
<value>-1</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>net.topology.script.number.args</name>
<value>100</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3n.multipart.uploads.block.size</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hfile.block.index.cacheonwrite</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.min-replication</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.admin.thread-count</name>
<value>1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.ha.zkfc.nn.http.timeout.ms</name>
<value>20000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.recovery.dir</name>
<value>${hadoop.tmp.dir}/yarn-nm-recovery</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.ssl.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.ftp.impl</name>
<value>org.apache.hadoop.fs.ftp.FtpFs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.handler-thread-count</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-metrics.unregister-delay-ms</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.column.max.version</name>
<value>1</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.caller.context.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.client.read.shortcircuit.buffer.size</name>
<value>131072</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>dfs.namenode.reject-unresolved-dn-topology-mapping</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.recovery.store.class</name>
<value>org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log.retain-seconds</name>
<value>10800</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.admin.address</name>
<value>${yarn.resourcemanager.hostname}:8033</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.recovery.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.slow.io.warning.threshold.ms</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.ha.automatic-failover.zk-base-path</name>
<value>/yarn-leader-election</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.viewfs.impl</name>
<value>org.apache.hadoop.fs.viewfs.ViewFs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.use.ipc.callq</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.blockreport.initialDelay</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.hdfs.impl</name>
<value>org.apache.hadoop.fs.Hdfs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.top.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.reservation-system.enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.retrycache.expirytime.millis</name>
<value>600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>zookeeper.recovery.retry.maxsleeptime</name>
<value>60000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.rest-csrf.browser-useragents-regex</name>
<value>^Mozilla.*,^Opera.*</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.speculative.speculative-cap-total-tasks</name>
<value>0.01</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.client.failover.sleep.max.millis</name>
<value>15000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.server-defaults.validity.period.ms</name>
<value>3600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.generic-application-history.max-applications</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.nm.uploader.thread-count</name>
<value>20</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log-container-debug-info.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.s3a.impl</name>
<value>org.apache.hadoop.fs.s3a.S3A</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.blocks.per.postponedblocks.rescan</name>
<value>10000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.property.clientPort</name>
<value>2181</value>
<final>false</final>
<source>hbase-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.max-completed-applications</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log-dirs</name>
<value>${yarn.log.dir}/userlogs</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.node-removal-untracked.timeout-ms</name>
<value>60000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.failover.sleep.base.millis</name>
<value>500</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern</name>
<value>^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.rest.readonly</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.default.chunk.view.size</name>
<value>32768</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.read.shortcircuit</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ftp.blocksize</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.acl-modify-job</name>
<value> </value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>zookeeper.znode.parent</name>
<value>/hbase</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.defaultFS</name>
<value>hdfs://hadoopmaster1:9000</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>hbase.rpc.shortoperation.timeout</name>
<value>10000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.node-labels.resync-interval-ms</name>
<value>120000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.http.filter.initializers</name>
<value>org.apache.hadoop.http.lib.StaticUserWebFilter</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3n.multipart.copy.block.size</name>
<value>5368709120</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.adl.impl</name>
<value>org.apache.hadoop.fs.adl.AdlFileSystem</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.adl.oauth2.access.token.provider.type</name>
<value>ClientCredential</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.connect.max-wait.ms</name>
<value>900000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.entity-group-fs-store.scan-interval-seconds</name>
<value>60</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.balancer.max-no-move-interval</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.ssl</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.max.extra.edits.segments.retained</name>
<value>10000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.https-address</name>
<value>0.0.0.0:50470</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
<final>false</final>
<source>mapred-site.xml</source>
</property>
<property>
<name>dfs.block.scanner.volume.bytes.per.second</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.intermediate-data-encryption.enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.store.class</name>
<value>org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.decommission.blocks.per.interval</name>
<value>500000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.mover.max-no-move-interval</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.fail-fast</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.admin.client.thread-count</name>
<value>1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.kms.client.encrypted.key.cache.size</name>
<value>500</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.shuffle.log.separate</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>ipc.client.kill.max</name>
<value>10</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.search.filter.group</name>
<value>(objectClass=group)</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.file.impl</name>
<value>org.apache.hadoop.fs.local.LocalFs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.hstore.compaction.min.size</name>
<value>134217728</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.http.authentication.kerberos.keytab</name>
<value>${user.home}/hadoop.keytab</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.client.nodemanager-connect.max-wait-ms</name>
<value>180000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.map.output.collector.class</name>
<value>org.apache.hadoop.mapred.MapTask$MapOutputBuffer</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.path.based.cache.retry.interval.ms</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.uid.cache.secs</name>
<value>14400</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.map.cpu.vcores</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.log-aggregation.retain-check-interval-seconds</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.map.log.level</name>
<value>INFO</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapred.child.java.opts</name>
<value>-Xmx200m</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.hard-kill-timeout-ms</name>
<value>10000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hfile.index.block.max.size</name>
<value>131072</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.client.scanner.timeout.period</name>
<value>60000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.session.timeout.ms</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.running.map.limit</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.store.in-memory.initial-delay-mins</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds</name>
<value>3600</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.client-server.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.local-cache.max-files-per-directory</name>
<value>8192</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.ipc.server.fallback-to-simple-auth-allowed</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.https.server.keystore.resource</name>
<value>ssl-server.xml</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.rest-csrf.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.ugi.expire.after.access</name>
<value>600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.handler.count</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.balancer.block-move.timeout</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>s3native.blocksize</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.client.completion.pollinterval</name>
<value>5000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.hstore.compactionThreshold</name>
<value>3</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.http.client.failover.sleep.max.millis</name>
<value>15000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.stream-buffer-size</name>
<value>4096</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.socket.send.buffer</name>
<value>8192</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.rest-csrf.custom-header</name>
<value>X-XSRF-HEADER</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.delegation.key.update-interval</name>
<value>86400000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.maps</name>
<value>2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.master.logcleaner.ttl</name>
<value>600000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.swebhdfs.impl</name>
<value>org.apache.hadoop.fs.SWebHdfs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.acl-view-job</name>
<value> </value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.s3a.readahead.range</name>
<value>64K</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.enable.retrycache</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.connect.retry-interval.ms</name>
<value>30000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms</name>
<value>300000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.multipart.threshold</name>
<value>2147483647</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.decommission.interval</name>
<value>30</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.rootdir.perms</name>
<value>700</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.hregion.majorcompaction</name>
<value>604800000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.max.connections</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>httpfs.buffer.size</name>
<value>4096</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.shell.safely.delete.limit.num.files</name>
<value>100</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.log-aggregation-enable</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client-write-packet-size</name>
<value>65536</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.file-block-storage-locations.timeout.millis</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.block.write.retries</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.task.io.sort.factor</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.security.dns.log-slow-lookups.threshold.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.hregion.memstore.flush.size</name>
<value>134217728</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ha.health-monitor.sleep-after-disconnect.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ha.zookeeper.session-timeout.ms</name>
<value>10000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.wal.dir.perms</name>
<value>700</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.transfer.socket.recv.buffer.size</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.quota.init-threads</name>
<value>4</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.input.fileinputformat.list-status.num-threads</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>io.skip.checksum.errors</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.ipc.client.tcpnodelay</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.regionserver.optionalcacheflushinterval</name>
<value>3600000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.lease-recheck-interval-ms</name>
<value>2000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.client.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.rest.csrf.enabled</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.safemode.extension</name>
<value>30000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.normalizer.period</name>
<value>300000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.move.thread-count</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.zk-state-store.parent-path</name>
<value>/rmstore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.client.fd-retain-secs</name>
<value>300</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>ipc.client.idlethreshold</name>
<value>4000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.regionserver.port</name>
<value>16020</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.cleaner.initial-delay-mins</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.accesstime.precision</name>
<value>3600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.task.profile.params</name>
<value>-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.hstore.time.to.purge.deletes</name>
<value>0</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.master.balancer.maxRitPercent</name>
<value>1.0</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.regionserver.logroll.errors.tolerated</name>
<value>2</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.keytab</name>
<value>/etc/security/keytab/jhs.service.keytab</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.hstore.compaction.max</name>
<value>10</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.hstore.compaction.throughput.lower.bound</name>
<value>52428800</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.scheduler.minimum-allocation-mb</name>
<value>1024</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs</name>
<value>86400</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.master.infoserver.redirect</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.fetch.retry.interval-ms</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.entity-group-fs-store.app-cache-size</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.user.group.static.mapping.overrides</name>
<value>dr.who=;</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.security.kms.client.encrypted.key.cache.low-watermark</name>
<value>0.3f</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.datanode.directoryscan.interval</name>
<value>21600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.connection.ssl.enabled</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.property.initLimit</name>
<value>10</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.node-labels.fs-store.retry-policy-spec</name>
<value>2000, 500</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.runtime.linux.docker.capabilities</name>
<value>CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.webhdfs.impl</name>
<value>org.apache.hadoop.fs.WebHdfs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.xframe.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.monitor.policies</name>
<value>org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>ipc.server.listen.queue.size</name>
<value>128</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>rpc.metrics.quantile.enable</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.system-reserved-memory-mb</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.domain.socket.path</name>
<value>none</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.client.nodemanager-client-async.thread-pool-max-size</name>
<value>500</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping</name>
<value>org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.system-metrics-publisher.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>/home/hadoop/data/nameNode</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>hbase.coprocessor.abortonerror</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.am.liveness-monitor.expiry-interval-ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nm.liveness-monitor.expiry-interval-ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.hstore.compaction.kv.max</name>
<value>10</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.hregion.preclose.flush.size</name>
<value>5242880</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ftp.bytes-per-checksum</name>
<value>512</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.nested-level</name>
<value>3</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.max.objects</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.master.hfilecleaner.plugins</name>
<value>org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner,org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner,org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>mapreduce.job.emit-timeline-data</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.map.memory.mb</name>
<value>1024</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.client.nodemanager-connect.retry-interval-ms</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.http.cross-origin.max-age</name>
<value>1800</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.edits.journal-plugin.qjournal</name>
<value>org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>nfs.wtmax</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.lease.recovery.dfs.timeout</name>
<value>64000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.edekcacheloader.initial.delay.ms</name>
<value>3000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.scheduler.include-port-in-node-name</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.speculative.retry-after-no-speculate</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.connection.timeout.ms</name>
<value>15000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.address</name>
<value>${yarn.resourcemanager.hostname}:8032</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>ipc.client.rpc-timeout.ms</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.cachereport.intervalMsec</name>
<value>10000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.task.skip.start.attempts</name>
<value>2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.s3a.socket.recv.buffer</name>
<value>8192</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.zk-timeout-ms</name>
<value>10000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.entity-group-fs-store.summary-store</name>
<value>org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.groups.cache.background.reload.threads</name>
<value>3</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.edits.dir</name>
<value>${dfs.namenode.checkpoint.dir}</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.server.scanner.max.result.size</name>
<value>104857600</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.hdfs.configuration.version</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.edits.asynclogging</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.cleaner.resource-sleep-ms</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.runtime.linux.allowed-runtimes</name>
<value>default</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.map.skip.maxrecords</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold</name>
<value>10737418240</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>nfs.allow.insecure.ports</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobtracker.system.dir</name>
<value>${hadoop.tmp.dir}/mapred/system</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.hostname</name>
<value>0.0.0.0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.registry.rm.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.job.reducer.preempt.delay.sec</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.dns.nameserver</name>
<value>default</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.ipc.server.callqueue.handler.factor</name>
<value>0.1</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.node-labels.configuration-type</name>
<value>centralized</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.ssl.enabled</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.vmem-pmem-ratio</name>
<value>2.1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-manager.thread-count</name>
<value>20</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.encrypt.data.transfer</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.block.access.key.update.interval</name>
<value>600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>/tmp/hadoop-${user.name}</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.audit.loggers</name>
<value>default</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.har.impl</name>
<value>org.apache.hadoop.fs.HarFs</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.localizer.cache.target-size-mb</name>
<value>10240</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.shuffle.log.backups</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.minicluster.use-rpc</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.http.policy</name>
<value>HTTP_ONLY</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.regionserver.logroll.period</name>
<value>3600000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.client.short.circuit.replica.stale.threshold.ms</name>
<value>1800000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.webapp.https.address</name>
<value>${yarn.timeline-service.hostname}:8190</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.amlauncher.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.http.client.failover.max.attempts</name>
<value>15</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>tfile.fs.output.buffer.size</name>
<value>262144</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.hregion.memstore.block.multiplier</name>
<value>4</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.checkpoint.check.period</name>
<value>60</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.dns.interface</name>
<value>default</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.regionserver.compaction.enabled</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.ftp.host.port</name>
<value>21</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.task.io.sort.mb</name>
<value>100</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.inotify.max.events.per.rpc</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.search.attr.group.name</name>
<value>cn</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.amrmproxy.address</name>
<value>0.0.0.0:8048</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.group.mapping.ldap.read.timeout.ms</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.avoid.read.stale.datanode</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.output.fileoutputformat.compress.type</name>
<value>RECORD</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.storescanner.parallel.seek.enable</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.snapshot.master.timeout.millis</name>
<value>300000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.regionserver.storefile.refresh.period</name>
<value>0</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.dfs.client.read.shortcircuit.buffer.size</name>
<value>131072</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.datanode.http.address</name>
<value>0.0.0.0:50075</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>file.bytes-per-checksum</name>
<value>512</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.image.compress</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ha.health-monitor.check-interval.ms</name>
<value>1000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.permissions.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.delegation.key.update-interval</name>
<value>86400000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.resource-tracker.client.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.domain.socket.data.traffic</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.image.compression.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.block.access.token.enable</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.address</name>
<value>0.0.0.0:50010</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.input.buffer.percent</name>
<value>0.0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.client.scanner.caching</name>
<value>2147483647</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.blockreport.intervalMsec</name>
<value>21600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.snapshot.restore.take.failsafe.snapshot</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ha.health-monitor.rpc-timeout.ms</name>
<value>45000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.datanode.bp-ready.timeout</name>
<value>20</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.failover.connection.retries</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.kerberos.internal.spnego.principal</name>
<value>${dfs.web.authentication.kerberos.principal}</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.policy.file</name>
<value>hbase-policy.xml</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.scheduler.maximum-allocation-mb</name>
<value>8192</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.leveldb-state-store.path</name>
<value>${hadoop.tmp.dir}/yarn/system/rmstore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.task.files.preserve.failedtasks</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.status.published</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.delete.thread-count</name>
<value>4</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.http.client.retry.policy.spec</name>
<value>10000,6,60000,10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.output.fileoutputformat.compress.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>map.sort.class</name>
<value>org.apache.hadoop.util.QuickSort</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.count-logical-processors-as-cores</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.jobname.limit</name>
<value>50</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.job.classloader</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.retry.ceiling.ms</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.blocksize</name>
<value>134217728</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>io.seqfile.compress.blocksize</name>
<value>1000000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.client.scanner.max.result.size</name>
<value>2097152</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.task.profile.maps</name>
<value>0-2</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.jobtracker.staging.root.dir</name>
<value>${hadoop.tmp.dir}/mapred/staging</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.localizer.cache.cleanup.interval-ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.regionserver.info.bindAddress</name>
<value>0.0.0.0</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.client.mmap.cache.timeout.ms</name>
<value>3600000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.http.cross-origin.allowed-origins</name>
<value>*</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.systemtables.compacting.memstore.type</name>
<value>NONE</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.client.fd-flush-interval-secs</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.edekcacheloader.interval.ms</name>
<value>1000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.java.secure.random.algorithm</name>
<value>SHA1PRNG</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.client.resolve.remote.symlinks</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.master.logcleaner.plugins</name>
<value>org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner,org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner,org.apache.hadoop.hbase.master.cleaner.TimeToLiveProcedureWALCleaner</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>yarn.resourcemanager.delegation-token-renewer.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.listen.queue.size</name>
<value>128</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.master.info.port.orig</name>
<value>16010</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>hbase.data.umask.enable</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.coprocessor.user.enabled</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>nfs.mountd.port</name>
<value>4242</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.disk-health-checker.min-healthy-disks</name>
<value>0.25</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.local.dir</name>
<value>${hbase.tmp.dir}/local/</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.resource.du.reserved</name>
<value>104857600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.job.end-notification.retry.interval</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.loadedjobs.cache.size</name>
<value>5</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.client.datanode-restart.timeout</name>
<value>30</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.fast.upload.active.blocks</name>
<value>4</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.local-dirs</name>
<value>${hadoop.tmp.dir}/nm-local-dir</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.table.lock.enable</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.client.perserver.requests.threshold</name>
<value>2147483647</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.datanode.block.id.layout.upgrade.threads</name>
<value>12</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.task.exit.timeout.check-interval-ms</name>
<value>20000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.storescanner.parallel.seek.threads</name>
<value>10</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.registry.jaas.context</name>
<value>Client</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.webapp.address</name>
<value>${yarn.timeline-service.hostname}:8188</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.address</name>
<value>0.0.0.0:10020</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.mob.file.cache.size</name>
<value>1000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ipc.server.log.slow.rpc</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>file.blocksize</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.datanode.readahead.bytes</name>
<value>4194304</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.cleaner.period-mins</name>
<value>1440</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.block.size</name>
<value>32M</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size</name>
<value>10485760</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.kms.client.failover.sleep.max.millis</name>
<value>2000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.property.dataDir</name>
<value>/home/hadoop/zookeeper/data</value>
<final>false</final>
<source>hbase-site.xml</source>
</property>
<property>
<name>yarn.resourcemanager.metrics.runtime.buckets</name>
<value>60,300,1440</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.http-address</name>
<value>0.0.0.0:50070</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.mob.compaction.threads.max</name>
<value>1</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.rest-csrf.methods-to-ignore</name>
<value>GET,OPTIONS,HEAD,TRACE</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ipc.client.ping</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.leveldb-state-store.compaction-interval-secs</name>
<value>3600</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.configuration.provider-class</name>
<value>org.apache.hadoop.yarn.LocalConfigurationProvider</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.recovery.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.hostname</name>
<value>0.0.0.0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.regionserver.handler.abort.on.error.percent</name>
<value>0.5</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.s3n.multipart.uploads.enabled</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.security.exec.permission.checks</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.disk-health-checker.enable</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.amrmproxy.interceptor-class.pipeline</name>
<value>org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.master.normalizer.class</name>
<value>org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-component-length</name>
<value>255</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.regionserver.info.port.auto</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ha.failover-controller.cli-check.rpc-timeout.ms</name>
<value>20000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.auth.key.update.interval</name>
<value>86400000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>ftp.client-write-packet-size</name>
<value>65536</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.parallelcopies</name>
<value>5</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.master.fileSplitTimeout</name>
<value>600000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.caller.context.signature.max.size</name>
<value>40</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.principal</name>
<value>jhs/_HOST@REALM.TLD</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.http.authentication.simple.anonymous.allowed</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.log-aggregation.retain-seconds</name>
<value>-1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.regionserver.thrift.framed</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.rm.container-allocation.expiry-interval-ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.property.maxClientCnxns</name>
<value>300</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.windows-container.cpu-limit.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.client.genericoptionsparser.used</name>
<value>true</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>yarn.timeline-service.http-authentication.simple.anonymous.allowed</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.kms.client.failover.sleep.base.millis</name>
<value>100</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.secondary.https-address</name>
<value>0.0.0.0:50091</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.jhist.format</name>
<value>json</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.mob.cache.evict.remain.ratio</name>
<value>0.5f</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.reservation-system.planfollower.time-step</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.ubertask.maxreduces</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.s3a.connection.establish.timeout</name>
<value>5000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.health-checker.interval-ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.rpc.client.event-loop.config</name>
<value>global-event-loop</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>dfs.namenode.fs-limits.max-xattr-size</name>
<value>16384</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.multipart.purge</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.security.kms.client.encrypted.key.cache.num.refill.threads</name>
<value>2</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.AbstractFileSystem.adl.impl</name>
<value>org.apache.hadoop.fs.adl.Adl</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.server.compactchecker.interval.multiplier</name>
<value>1000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.store-class</name>
<value>org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.transfer.buffer.size</name>
<value>131072</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.zk-num-retries</name>
<value>1000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.store.in-memory.staleness-period-mins</name>
<value>10080</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.webapp.address</name>
<value>${yarn.nodemanager.hostname}:8042</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.client-am.ipc.max-retries</name>
<value>3</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>ipc.ping.interval</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ha.failover-controller.new-active.rpc-timeout.ms</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.client.thread-count</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.block-placement-policy.default.prefer-local-node</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.trash.interval</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.client.max.perregion.tasks</name>
<value>1</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.fileoutputcommitter.algorithm.version</name>
<value>1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.skip.maxgroups</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.top.windows.minutes</name>
<value>1,5,25</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.memory.mb</name>
<value>1024</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.health-checker.script.timeout-ms</name>
<value>1200000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.du.reserved</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.master.mob.ttl.cleaner.period</name>
<value>86400</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.resource.check.interval</name>
<value>5000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.client.progressmonitor.pollinterval</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.delegation.token.renew-interval</name>
<value>86400000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.hostname</name>
<value>0.0.0.0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.ha.enabled</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.ha.log-roll.period</name>
<value>120</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.scheduler.minimum-allocation-vcores</name>
<value>1</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.best-effort</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.container.log.limit.kb</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.http.authentication.signature.secret.file</name>
<value>${user.home}/hadoop-http-auth-signature-secret</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.move.interval-ms</name>
<value>180000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs</name>
<value>86400</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-executor.class</name>
<value>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.security.authorization</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.storage.policy.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.https.address</name>
<value>0.0.0.0:50475</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.localizer.address</name>
<value>${yarn.nodemanager.hostname}:8040</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.replication.min</name>
<value>1</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.recovery.store.fs.uri</name>
<value>${hadoop.tmp.dir}/mapred/history/recoverystore</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.shuffle.connection-keep-alive.enable</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.top.num.users</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.common.configuration.version</name>
<value>0.23.0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.task.container.log.backups</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.namenode.fslock.fair</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.groups.negative-cache.secs</name>
<value>30</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.mob.compaction.mergeable.threshold</name>
<value>1342177280</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.ifile.readahead</name>
<value>true</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hadoop.security.kms.client.timeout</name>
<value>60</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.resource.percentage-physical-cpu-limit</name>
<value>100</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.max.split.locations</name>
<value>10</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.datanode.max.locked.memory</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.registry.zk.quorum</name>
<value>localhost:2181</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>fs.s3a.threads.keepalivetime</name>
<value>60</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.joblist.cache.size</name>
<value>20000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.job.end-notification.max.attempts</name>
<value>5</value>
<final>true</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.image.transfer.timeout</name>
<value>60000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.read.shortcircuit.skip.checksum</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hadoop.security.groups.cache.background.reload</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>nfs.rtmax</name>
<value>1048576</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.namenode.edit.log.autoroll.check.interval.ms</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.connect.timeout</name>
<value>180000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.datanode.failed.volumes.tolerated</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.webapp.address</name>
<value>0.0.0.0:19888</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>fs.s3a.connection.timeout</name>
<value>200000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.xframe.value</name>
<value>SAMEORIGIN</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.client.mmap.retry.timeout.ms</name>
<value>300000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.data.dir.perm</name>
<value>700</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.nm.uploader.replication.factor</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.http.authentication.token.validity</name>
<value>36000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ipc.client.connect.max.retries.on.timeouts</name>
<value>45</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.regionserver.hostname.disable.master.reversedns</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.client.internal-timers-ttl-secs</name>
<value>420</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.docker-container-executor.exec-name</name>
<value>/usr/bin/docker</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.job.committer.cancel-timeout</name>
<value>60000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.ha.fencing.ssh.connect-timeout</name>
<value>30000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.data.umask</name>
<value>000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.log.level</name>
<value>INFO</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.shuffle.merge.percent</name>
<value>0.66</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>ipc.client.fallback-to-simple-auth-allowed</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>io.serializations</name>
<value>org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.regionserver.hlog.writer.impl</name>
<value>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.s3.block.size</name>
<value>67108864</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user</name>
<value>nobody</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.kerberos.kinit.command</name>
<value>kinit</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hadoop.security.kms.client.encrypted.key.cache.expiry</name>
<value>43200000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.fs.state-store.uri</name>
<value>${hadoop.tmp.dir}/yarn/system/rmstore</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.client.block.write.locateFollowingBlock.initial.delay.ms</name>
<value>400</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.dispatcher.drain-events.timeout</name>
<value>300000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.regionserver.region.split.policy</name>
<value>org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.cells.scanned.per.heartbeat.check</name>
<value>10000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.admin.acl</name>
<value>*</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.mob.compactor.class</name>
<value>org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.namenode.delegation.token.max-lifetime</name>
<value>604800000</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.reduce.merge.inmem.threshold</name>
<value>1000</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.cluster.max-application-priority</name>
<value>0</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.webhdfs.socket.connect-timeout</name>
<value>60s</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.datanode.metrics.logger.period.seconds</name>
<value>600</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>net.topology.impl</name>
<value>org.apache.hadoop.net.NetworkTopology</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.ha.automatic-failover.enabled</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.use.datanode.hostname</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>dfs.heartbeat.interval</name>
<value>3</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.scheduler.class</name>
<value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>io.map.index.skip</name>
<value>0</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>dfs.namenode.handler.count</name>
<value>10</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.webapp.https.address</name>
<value>${yarn.resourcemanager.hostname}:8090</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.regionserver.majorcompaction.pagecache.drop</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.admin-env</name>
<value>MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.client.max.total.tasks</name>
<value>100</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.security.crypto.cipher.suite</name>
<value>AES/CTR/NoPadding</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.task.profile.map.params</name>
<value>${mapreduce.task.profile.params}</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.zookeeper.peerport</name>
<value>2888</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.security.crypto.buffer.size</name>
<value>8192</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.table.max.rowsize</name>
<value>1073741824</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.container-metrics.enable</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.s3a.path.style.access</name>
<value>false</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.cluster.acls.enabled</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.uploader.server.address</name>
<value>0.0.0.0:8046</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.datanode.http.internal-proxy.port</name>
<value>0</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.client.operation.timeout</name>
<value>1200000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.regionserver.info.port</name>
<value>16010</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>yarn.log-aggregation-status.time-out.ms</name>
<value>600000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>dfs.namenode.lock.detailed-metrics.enabled</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>fs.s3a.threads.max</name>
<value>10</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.coprocessor.enabled</name>
<value>true</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.hregion.majorcompaction.jitter</name>
<value>0.50</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.snapshot.region.timeout</name>
<value>300000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.har.impl.disable.cache</name>
<value>true</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>ipc.client.connect.timeout</name>
<value>20000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.remote-app-log-dir-suffix</name>
<value>logs</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>fs.df.interval</name>
<value>60000</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.regionserver.thrift.framed.max_frame_size_in_mb</name>
<value>2</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.http.filter.initializers</name>
<value>org.apache.hadoop.hbase.http.lib.StaticUserWebFilter</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hadoop.util.hash.type</name>
<value>murmur</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.minicluster.fixed.ports</name>
<value>false</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.shuffle.log.limit.kb</name>
<value>0</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.client.failover.max.attempts</name>
<value>15</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.master.loadbalance.bytable</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>dfs.client.use.datanode.hostname</name>
<value>false</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>ha.zookeeper.acl</name>
<value>world:anyone:rwcda</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>yarn.timeline-service.entity-group-fs-store.done-dir</name>
<value>/tmp/entity-file-history/done/</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.replication.rpc.codec</name>
<value>org.apache.hadoop.hbase.codec.KeyValueCodecWithTags</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.delegation.token.max-lifetime</name>
<value>604800000</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.job.speculative.speculative-cap-running-tasks</name>
<value>0.1</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.map.sort.spill.percent</name>
<value>0.80</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.nodemanager.recovery.supervised</name>
<value>false</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>file.stream-buffer-size</name>
<value>4096</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.meta.replicas.use</name>
<value>false</value>
<final>false</final>
<source>programatically</source>
</property>
<property>
<name>yarn.resourcemanager.ha.automatic-failover.embedded</name>
<value>true</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.master.wait.on.service.seconds</name>
<value>30</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.rpc.rows.warning.threshold</name>
<value>5000</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.security.authentication</name>
<value>simple</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.nodemanager.minimum.version</name>
<value>NONE</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hadoop.fuse.connection.timeout</name>
<value>300</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>hbase.client.keyvalue.maxsize</name>
<value>10485760</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size</name>
<value>10</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>hbase.regionserver.thrift.compact</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>hbase.hstore.compaction.ratio</name>
<value>1.2F</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>yarn.sharedcache.webapp.address</name>
<value>0.0.0.0:8788</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>yarn.app.mapreduce.am.resource.mb</name>
<value>1536</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.framework.name</name>
<value>local</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>mapreduce.job.reduce.slowstart.completedmaps</name>
<value>0.05</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>yarn.resourcemanager.client.thread-count</name>
<value>50</value>
<final>false</final>
<source>yarn-default.xml</source>
</property>
<property>
<name>mapreduce.cluster.temp.dir</name>
<value>${hadoop.tmp.dir}/mapred/temp</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>dfs.client.mmap.enabled</name>
<value>true</value>
<final>false</final>
<source>hdfs-default.xml</source>
</property>
<property>
<name>mapreduce.jobhistory.intermediate-done-dir</name>
<value>${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate</value>
<final>false</final>
<source>mapred-default.xml</source>
</property>
<property>
<name>hbase.defaults.for.version.skip</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
<property>
<name>fs.s3a.attempts.maximum</name>
<value>20</value>
<final>false</final>
<source>core-default.xml</source>
</property>
<property>
<name>hbase.rest.support.proxyuser</name>
<value>false</value>
<final>false</final>
<source>hbase-default.xml</source>
</property>
</configuration>
